{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook will downsample lightsheet data\n",
    "# from here\n",
    "#  /panfs/dong/3D_stitched_LS/20220725_SW220510_02_LS_6x_1000z\n",
    "#  note we will  now load voxel size from the data itself\n",
    "# and we load the extent as well\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in v01 I look at standard deviation too\n",
    "\n",
    "I'd also like to find the minimum value in the dataset other than 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE\n",
    "if any part of a chunk is accessed, the whole chunk is read.\n",
    "\n",
    "I should be able to speed things up by reading 64 slices at a time (potentially).\n",
    "\n",
    "\"\n",
    "Typical chunk sizes are 128x128x64 or 256x256x16. The optimal chunk size is determined by the geometry of the image and it is not easy to specify rules for reproducing exactly the chunk sizes that Imaris will write into the hdf-file.\n",
    "\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import os\n",
    "from glob import glob\n",
    "from os.path import join as pathjoin\n",
    "import h5py\n",
    "import time\n",
    "\n",
    "import imp\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "import donglab_workflows as dw\n",
    "imp.reload(dw)\n",
    "import PIL.Image as Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import tifffile as tf # for 16 bit tiff\n",
    "import h5py\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo, move into dongloab workflows and use for dragonfly as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# downsample lightsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mit data is stored in tif stacks\n",
    "the size is\n",
    "Image resolution is 1.8 µm x 1.8 µm x 2.0 µm (xyz), and the stack can be found at our network storage space at BMAP.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input path, can be a directory or a filename\n",
    "#input_path = '/home/dtward/bmaproot/panfs/dong/3D_stitched_LS/20220725_SW220510_02_LS/SW220510_02_LS_6x_1000z.ims'\n",
    "input_path = '/panfs/dong/3D_stitched_LS/20220725_SW220510_02_LS/SW220510_02_LS_6x_1000z.ims'\n",
    "image_type = 'ims' # can be ims or Tif\n",
    "\n",
    "output_filename = None # generate automatically if None\n",
    "\n",
    "# we need a temporary output directory for intermediate results (each slice)\n",
    "#outdir = '/home/dtward/bmaproot/nafs/dtward/dong/donglab_resample_lightsheet_good_2022_09_06_tmp'\n",
    "outdir = '/nafs/dtward/dong/donglab_resample_lightsheet_good_2022_09_06_tmp'\n",
    "\n",
    "# res is the desired voxel size\n",
    "dI = None # if none will load from data\n",
    "res = 50.0 # perhaps we could use the 25 micron atlas (this can be any float)\n",
    "channel = 0\n",
    "dataset_string = f'DataSet/ResolutionLevel 0/TimePoint 0/Channel {channel}/Data' # not used for Tifs\n",
    "\n",
    "# power to reduce dynamic range\n",
    "power = np.ones(1,dtype=np.float32)*0.125\n",
    "\n",
    "# blocksize and chunksize for looking for areas with no data and loading quickly\n",
    "blocksize = 64 # \n",
    "chunksize = 32 # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/home/dtward/bmaproot/panfs/dong/3D_stitched_LS/20220725_SW220510_02_LS/SW220510_02_LS_6x_1000z.ims', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3060908/1530591689.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdI\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimage_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'ims'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimaris_get_pixel_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mxI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimaris_get_x\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/intelpython3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, **kwds)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 533\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/intelpython3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/home/dtward/bmaproot/panfs/dong/3D_stitched_LS/20220725_SW220510_02_LS/SW220510_02_LS_6x_1000z.ims', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "if dI is None and image_type == 'ims':\n",
    "    f = h5py.File(input_path,'r')\n",
    "    dI = dw.imaris_get_pixel_size(f)    \n",
    "    xI = dw.imaris_get_x(f)\n",
    "    f.close()\n",
    "    \n",
    "if output_filename is None:\n",
    "    output_filename = os.path.splitext(os.path.split(input_path)[-1])[0] + '_ch_' + str(channel) + '_pow_' + str(power) + '_down.npz'\n",
    "#output_filename = 'SYTO16_488_086780_109130_down.npz'    \n",
    "\n",
    "print(f'Input path is {input_path}')\n",
    "print(f'Output filename is {output_filename}')\n",
    "print(f'Resolution is {dI}')\n",
    "print(f'Desired resolution is {res}')\n",
    "print(f'Dataset string is {dataset_string}')\n",
    "print(f'tmp output dir is {outdir}')\n",
    "\n",
    "# temporary output dir\n",
    "os.makedirs(outdir,exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want 50 micron\n",
    "down = np.floor(res/dI).astype(int)\n",
    "print(f'Downsampling factors are {down}')\n",
    "print(f'Downsampled res {dI*down}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a tif class with similar interface\n",
    "class TifStack:\n",
    "    '''We need a tif stack with an interface that will load a slice one at a time\n",
    "    We assume each tif has the same size\n",
    "    We assume 16\n",
    "    '''\n",
    "    def __init__(self,input_directory,pattern='*.tif'):\n",
    "        self.input_directory = input_directory\n",
    "        self.pattern = pattern\n",
    "        self.files = glob(pathjoin(input_directory,pattern))\n",
    "        self.files.sort()\n",
    "        test = Image.open(self.files[0])\n",
    "        self.nxy = test.size\n",
    "        test.close()\n",
    "        self.nz = len(self.files)\n",
    "        self.shape = (self.nz,self.nxy[1],self.nxy[0]) # note, it is xy not rowcol\n",
    "    def __getitem__(self,i):\n",
    "        return tf.imread(self.files[i])/(2**16-1)\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def close(self):\n",
    "        pass # nothing necessary\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "\n",
    "if image_type == 'tif':\n",
    "    data = TifStack(input_directory)\n",
    "    \n",
    "elif image_type == 'ims':\n",
    "    data_ = h5py.File(input_path,mode='r')\n",
    "    data = data_[dataset_string]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset shape {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nI = np.array(data.shape)\n",
    "#xI = [np.arange(n)*d - (n-1)/2.0*d for n,d in zip(nI,dI)] # already computed above\n",
    "# NOTE: the imaging data is smaller than the saved data because the saved data is a multiple of 64\n",
    "nIreal = np.array([len(x) for x in xI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xId = [dw.downsample(x,[d]) for x,d in zip(xI,down)]\n",
    "dId = [x[1]-x[0] for x in xId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# okay now I have to iterate over the dataset\n",
    "# note this is currently not doing wieghts\n",
    "# we need to save intermediate outputs (each slice) in case of errors\n",
    "fig,ax = plt.subplots(2,2)\n",
    "ax = ax.ravel()\n",
    "working = []\n",
    "working2 = []\n",
    "workingw = []\n",
    "output = []\n",
    "output2 = []\n",
    "outputw = []\n",
    "start = time.time()\n",
    "for i in range(nIreal[0]):\n",
    "    starti = time.time()\n",
    "    outname = os.path.join(outdir,f'{i:06d}_s.npy')\n",
    "    \n",
    "\n",
    "\n",
    "    if os.path.exists(outname):\n",
    "        # what happens if it fails in the middle of a chunk?\n",
    "        sd = np.load(outname)\n",
    "        s2d = np.load(outname.replace('_s','_s2'))\n",
    "        wd = np.load(outname.replace('_s','_w'))\n",
    "    else:\n",
    "        # load a whole chunk\n",
    "        if not i%chunksize:\n",
    "            data_chunk = data[i:i+chunksize]\n",
    "        # use this for weights\n",
    "        #s_all = data[i,:,:]\n",
    "        # it's possible that this will fail if I haven't defined data_chunk yet\n",
    "        try:\n",
    "            s_all = data_chunk[i%chunksize,:,:]\n",
    "        except:\n",
    "            # we need to load, not starting at i\n",
    "            # but at the beginning of the chunk\n",
    "            data_chunk = data[i//chunksize:i//chunksize+chunksize]\n",
    "            s_all = data_chunk[i%chunksize,:,:]\n",
    "        s = s_all[:nIreal[1]+1,:nIreal[2]+1]**power # test reduce dynamic range before downsampling with this power\n",
    "        s2 = s**2\n",
    "        #w = (s>0).astype(float)\n",
    "        # this is not a good way to get weights, \n",
    "        # we need to look for a 64x64 block of all zeros\n",
    "        \n",
    "        s_all_block = s_all.reshape(s_all.shape[0]//blocksize,blocksize,s_all.shape[1]//blocksize,blocksize)\n",
    "        tmp = np.logical_not(np.all(s_all_block==0,axis=(1,3))).astype(np.uint8)\n",
    "        s_all_w = np.ones_like(s_all_block)\n",
    "        s_all_w *= tmp[:,None,:,None]\n",
    "        s_all_w = s_all_w.reshape(s_all.shape)\n",
    "        w = s_all_w[:nIreal[1]+1,:nIreal[2]+1].astype(power.dtype)\n",
    "\n",
    "        \n",
    "        sd = dw.downsample((s*w),down[1:])\n",
    "        s2d = dw.downsample((s2*w),down[1:])\n",
    "        wd = dw.downsample(w,down[1:])\n",
    "        sd /= wd\n",
    "        sd[np.isnan(sd)] = 0.0\n",
    "        s2d /= wd\n",
    "        s2d[np.isnan(s2d)] = 0.0\n",
    "        \n",
    "        np.save(outname,sd)\n",
    "        np.save(outname.replace('_s','_w'),wd)\n",
    "        np.save(outname.replace('_s','_s2'),s2d)\n",
    "    \n",
    "    ax[0].cla()\n",
    "    wd0 = wd>0.0\n",
    "    if np.any(wd0):\n",
    "        vmin = np.min(sd[wd0])\n",
    "        vmax = np.max(sd[wd0])\n",
    "    else:\n",
    "        vmin = None\n",
    "        vmax = None\n",
    "    ax[0].cla()\n",
    "    ax[0].imshow(sd,vmin=vmin,vmax=vmax)\n",
    "    ax[2].cla()\n",
    "    ax[2].imshow(wd,vmin=0,vmax=1)\n",
    "    working.append(sd)\n",
    "    working2.append(s2d)\n",
    "    workingw.append(wd)\n",
    "    \n",
    "    if len(working) == down[0]:\n",
    "        workingw_stack = np.stack(workingw)\n",
    "        out = dw.downsample(np.stack(working)*workingw_stack,[down[0],1,1])\n",
    "        out2 = dw.downsample(np.stack(working2)*workingw_stack,[down[0],1,1])\n",
    "        outw = dw.downsample(workingw_stack,[down[0],1,1])        \n",
    "        out /= outw\n",
    "        out[np.isnan(out)] = 0.0\n",
    "        out2 /= outw\n",
    "        out2[np.isnan(out2)] = 0.0\n",
    "        outstd = out2 - out**2\n",
    "        outstd[outstd<0]=0\n",
    "        outstd = np.sqrt(outstd)\n",
    "        wd0 = (wd>0.0)[None]\n",
    "        if np.any(wd0):\n",
    "            outshow = (out[0] - np.min(out[wd0]))/(np.quantile(out[wd0],0.99) - np.min(out[wd0]))\n",
    "            outshowstd = (outstd[0] - np.min(outstd[wd0]))/(np.quantile(outstd[wd0],0.99) - np.min(outstd[wd0]))\n",
    "        else:\n",
    "            outshow = (out[0] - np.min(out))/(np.quantile(out,0.99) - np.min(out))\n",
    "            outshowstd = (outstd[0] - np.min(outstd))/(np.quantile(outstd,0.99) - np.min(outstd))\n",
    "        ax[1].cla()\n",
    "        ax[1].imshow(np.stack((outshow,outshowstd,outshow),-1))\n",
    "        ax[3].cla()\n",
    "        ax[3].imshow(outw[0],vmin=0,vmax=1)\n",
    "        output.append(out)\n",
    "        output2.append(out2)\n",
    "        outputw.append(outw)\n",
    "        working = []\n",
    "        workingw = []\n",
    "        working2 = []\n",
    "    fig.suptitle(f'slice {i} of {data.shape[0]}')\n",
    "    fig.canvas.draw()\n",
    "    print(f'Finished loading slice {i} of {data.shape[0]}, time {time.time() - starti} s')\n",
    "output = np.concatenate(output)        \n",
    "Id = output\n",
    "wd = np.concatenate(outputw)\n",
    "print(f'Finished downsampling, time {time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(output_filename,I=Id,I2=np.concatenate(output2),xI=np.array(xId,dtype='object'),w=wd) # note specify object to avoid \"ragged\" warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = dw.draw_slices(Id,xId)\n",
    "fig.suptitle(output_filename)\n",
    "fig.savefig(output_filename.replace('npz','jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
